# -*- coding: utf-8 -*-
"""OT_GAN_II.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R6oBPQpX_y_V8b2Uy_TJZGPJqMs9giuV
"""

import tensorflow as tf
import numpy as np
import cv2
from matplotlib import pyplot as plt

(x, _), (_, _) = tf.keras.datasets.mnist.load_data()



#images=np.reshape(x,(60000,64,64,1))
images=[]
for i in range (len(x)):
    images.append(cv2.resize(x[i], (64,64), interpolation = cv2.INTER_AREA))

images=np.array(images)
images=np.resize(images,(60000,64,64,1))

images = (images - 127.5) / 127.5

from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Flatten, Input, LeakyReLU, Dense
from tensorflow.keras import initializers
from tensorflow.keras.models import Model

initializer = initializers.GlorotUniform()

def critic():
    input_image = Input(shape=(64, 64, 1))

    x = Conv2D(64,
                      (5, 5),
                      strides=(2, 2),
                      padding='same',
                      kernel_initializer=initializer)(input_image)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(128,
                      (5, 5),
                      strides=(2, 2),
                      padding='same',
                      kernel_initializer=initializer)(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(256,
                      (5, 5),
                      strides=(2, 2),
                      padding='same',
                      kernel_initializer=initializer)(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(512,
                      (5, 5),
                      strides=(3, 3),
                      padding='valid',
                      kernel_initializer=initializer)(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Flatten()(x)
    x = tf.math.l2_normalize(x)

    return Model(inputs=input_image, outputs=x)

critic = critic()

critic.summary()

def generator():
    input_noise = Input(shape=(1, 1, 2048))

    x = Conv2DTranspose(512,
                        kernel_size=4,
                        strides=1,
                        padding="valid",
                        kernel_initializer=initializer)(input_noise)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2DTranspose(256,
                        kernel_size=5,
                        strides=2,
                        padding="same",
                        kernel_initializer=initializer)(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2DTranspose(128,
                        kernel_size=5,
                        strides=2,
                        padding="same",
                        kernel_initializer=initializer)(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2DTranspose(128,
                        kernel_size=5,
                        strides=2,
                        padding="same",
                        kernel_initializer=initializer)(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2DTranspose(1,
                        kernel_size=5,
                        strides=2,
                        padding="same",
                        activation="tanh",
                        kernel_initializer=initializer)(x)
    return Model(inputs=input_noise, outputs=x)

generator = generator()

generator.summary()

# Test cell
batch_size = 200

X = images[:batch_size]
batch_x = critic(X, training=False)

y = tf.random.normal(shape=(batch_size,1,1,2048))
Y = generator(y, training=False)
batch_y = critic(Y, training=False)

batch_x.shape, batch_y.shape

def cost_function(batch_x, batch_y):
    
    # Cosine similarity
    similarity = tf.reduce_sum(batch_x[:, tf.newaxis] * batch_y, axis=-1)
    similarity /= (tf.norm(batch_x[:, tf.newaxis], axis=-1) * tf.norm(batch_y, axis=-1) +1e-12)
    # Computing the distance
    distance = 1 - similarity
    return distance

cost_function(batch_x, batch_y)

def sinkhorn(C, batch_size, epsilon=0.1, max_iters=100, delta = 1e-3):
    # Computing the kernel matrix
    K = tf.math.exp(-C/epsilon)
    a = tf.ones(batch_size)
    b = tf.ones(batch_size)
    # Alternate projections
    v = tf.ones(b.shape[0])
    for _ in range(max_iters):
        u = tf.divide(a, tf.linalg.matvec(K, v))
        v = tf.divide(b, tf.linalg.matvec(K, u))
    diag_u = tf.linalg.diag(tf.reshape(u, shape=b.shape[0]))
    diag_v = tf.linalg.diag(tf.reshape(v, shape=b.shape[0]))
    # Returning the soft matching
    return tf.linalg.matmul(tf.linalg.matmul(diag_u, K), diag_v)

def train_OTGAN(X1, X2, update_gen=False):
    batch_size = X1.shape[0]

    # Recording all the operations for the gradient computing
    with tf.GradientTape(persistent=True) as tape:

        # Generating the random noise
        y1 = tf.random.uniform(shape=(batch_size,1,1,2048), minval=-1, maxval=1)
        y2 = tf.random.uniform(shape=(batch_size,1,1,2048), minval=-1, maxval=1)

        # Generating the fake images from the noise
        Y1 = generator(y1, training=True)
        Y2 = generator(y2, training=True)

        # Getting the latent vectors from the critic
        batch_x1 = critic(X1, training=True)
        batch_x2 = critic(X2, training=True)
        batch_y1 = critic(Y1, training=True)
        batch_y2 = critic(Y1, training=True)

        # Computing the cost matrices for each couple
        C_x1_y1 = cost_function(batch_x1, batch_y1) 
        C_x1_y2 = cost_function(batch_x1, batch_y2) 
        C_x2_y1 = cost_function(batch_x2, batch_y1) 
        C_x2_y2 = cost_function(batch_x2, batch_y2) 
        C_x1_x2 = cost_function(batch_x1, batch_x2)
        C_y1_y2 = cost_function(batch_y1, batch_y2)

        # Getting the soft matching of each couple
        M_x1_y1 = sinkhorn(C_x1_y1, batch_size)
        M_x1_y2 = sinkhorn(C_x1_y2, batch_size)
        M_x2_y1 = sinkhorn(C_x2_y1, batch_size)
        M_x2_y2 = sinkhorn(C_x2_y2, batch_size)
        M_x1_x2 = sinkhorn(C_x1_x2, batch_size)
        M_y1_y2 = sinkhorn(C_y1_y2, batch_size)

        # Finally getting the loss
        loss_x1_y1 = tf.linalg.trace(tf.matmul(M_x1_y1, tf.transpose(C_x1_y1)))
        loss_x1_y2 = tf.linalg.trace(tf.matmul(M_x1_y2, tf.transpose(C_x1_y2)))
        loss_x2_y1 = tf.linalg.trace(tf.matmul(M_x2_y1, tf.transpose(C_x2_y1)))
        loss_x2_y2 = tf.linalg.trace(tf.matmul(M_x2_y2, tf.transpose(C_x2_y2)))
        loss_x1_x2 = tf.linalg.trace(tf.matmul(M_x1_x2, tf.transpose(C_x1_x2)))
        loss_y1_y2 = tf.linalg.trace(tf.matmul(M_y1_y2, tf.transpose(C_y1_y2)))

        # Computing the losses
        loss_critic = 2*loss_x1_x2 + 2*loss_y1_y2
        loss_generator = loss_x1_y1 + loss_x1_y2 + loss_x2_y1 + loss_x2_y2
        total_loss = loss_generator - loss_critic
    
    # Updating the generator gradients when needed
    if update_gen==True:
        grads_generator = tape.gradient(total_loss, generator.trainable_variables)
        optimizer_g.apply_gradients(zip(grads_generator, generator.trainable_variables))

    # Updating the critic gradients
    grads_critic = -1 * tape.gradient(total_loss, critic.trainable_variables)
    optimizer_c.apply_gradients(zip(grads_critic, critic.trainable_variables))

    return total_loss, loss_critic, loss_generator

# Function to display the outputs of the generator throughout training
def generate_and_save_images(model, epoch, test_input):
    predictions = model(test_input, training=False)

    fig = plt.figure(figsize=(4, 4))

    for i in range(16):
        plt.subplot(4, 4, i+1)
        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
        plt.axis('off')

    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()

from tensorflow.keras.optimizers import Adam

# Parameters of the training
n_gen = 3                       # Updating the generator every x iterations
epochs = 10                     # Number of epochs
batch_size = 200                # Batch size
size = images.shape[0]
n = 60000                       # Number of observations used
lr = 1e-3                       # Learning rate
beta1 = 0.9
beta2 = 0.999
epsilon = 0.01                  # Regularization parameter

# Defining our optimizers
optimizer_c = Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2)
optimizer_g = Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2)

# Preparing the data into batches
images_data = tf.data.Dataset.from_tensor_slices(images[:n]).shuffle(size).batch(batch_size*2, drop_remainder=True)

# Defining a random noise that will be used throughout training
seed = tf.random.uniform(shape=(batch_size,1,1,2048), minval=-1, maxval=1)

for epoch in range(epochs):
    print("====== Epoch {:2d} ======".format(epoch))

    for i, real_images in enumerate(images_data):
        print(i, end=" ... ")

        # Splitting the batch into two parts
        X1 = real_images[:batch_size]
        X2 = real_images[batch_size:]

        # Deciding when to update the generator
        if i % n_gen == 0 and i > 0:
            update_gen = True
        else:
            update_gen = False
        
        # Running the train loop
        total_loss, loss_critic, loss_generator = train_OTGAN(X1, X2, update_gen=update_gen)

        print('\nTotal Loss : {}'.format(total_loss.numpy()))
        print('Loss Critic : {}'.format(loss_critic.numpy()))
        print('Loss Generator : {}'.format(loss_generator.numpy()))

        # Displaying the results
        if i % 5 == 0 and i > 0:
            generate_and_save_images(generator, epoch*1000 + i + 1, seed)

images2 = x
images2 = (images2 - 127.5) / 127.5
images2 = tf.cast(images2, dtype=tf.float32)

def generator2():
    input_noise = Input(shape=(1, 1, 2))

    x = Dense(500, kernel_initializer='glorot_uniform')(input_noise)
    x = Dense(28*28, kernel_initializer='glorot_uniform')(x)

    return Model(inputs=input_noise, outputs=x)

generator2 = generator2()

generator2.summary()

def cost_function2(batch_x, batch_y):
    # Cosine similarity
    similarity = tf.reduce_sum(batch_x[:, tf.newaxis] * batch_y, axis=[-2,-1])
    similarity /= ((tf.reduce_sum(tf.square(batch_x), axis=[-2,-1])+1e-12 )* tf.reduce_sum(tf.square(batch_y), axis=[-2,-1]) +1e-12)+1e-12
    # Computing the distance
    distance = 1 - similarity
    return distance

def train_OTGAN2(X):
    batch_size = X.shape[0]

    # Recording all the operations for the gradient computing
    with tf.GradientTape() as tape:

        # Generating the random noise
        z = tf.random.uniform(shape=(batch_size,1,1,2), minval=0, maxval=1)

        # Generating the fake images from the noise
        Y = generator2(z, training=True)
        Y = tf.reshape(Y, shape=[batch_size, 28, 28])

        # Computing the cost matrices
        C_XY = cost_function2(X, Y)
        C_XX = cost_function2(X, X)
        C_YY = cost_function2(Y, Y)

        # Getting the soft matching
        M_XY = sinkhorn(C_XY, batch_size)
        M_XX = sinkhorn(C_XX, batch_size)
        M_YY = sinkhorn(C_YY, batch_size)

        # Finally getting the loss
        loss_XY = tf.linalg.trace(tf.matmul(M_XY, tf.transpose(C_XY)))
        loss_XX = tf.linalg.trace(tf.matmul(M_XX, tf.transpose(C_XX)))
        loss_YY = tf.linalg.trace(tf.matmul(M_YY, tf.transpose(C_YY)))

        # Computing the loss
        loss = 2 * loss_XY - loss_XX - loss_YY
    
    grads_generator = tape.gradient(loss, generator2.trainable_variables)
    optimizer.apply_gradients(zip(grads_generator, generator2.trainable_variables))

    return loss

from tensorflow.keras.optimizers import Adam

# Parameters of the training
epochs = 10                     # Number of epochs
batch_size = 200                # Batch size
size = images2.shape[0]
n = 60000                       # Number of observations used
lr = 1e-3                       # Learning rate
beta1 = 0.9
beta2 = 0.999
epsilon = 1                     # Regularization parameter

# Defining our optimizers
optimizer = Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2)

# Preparing the data into batches
images_data = tf.data.Dataset.from_tensor_slices(images2[:n]).shuffle(size).batch(batch_size, drop_remainder=True)

# Defining a random noise that will be used throughout training
seed = tf.random.uniform(shape=(batch_size,1,1,2), minval=0, maxval=1)

for epoch in range(epochs):
    print("====== Epoch {:2d} ======".format(epoch))

    for i, real_images in enumerate(images_data):
        print(i, end=" ... ")

        # Splitting the batch into two parts
        X = real_images
        
        # Running the train loop
        loss = train_OTGAN2(X)

        print('\nLoss : {}'.format(loss.numpy()))
        # Displaying the results
        if i % 5 == 0 and i > 0:
            generate_and_save_images(generator2, epoch*1000 + i + 1, seed)

